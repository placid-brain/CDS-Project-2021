{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4U1mUelTsOg"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "flqeqowmPlN4",
    "outputId": "08c6d57b-9a84-48db-a511-00401b090c58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('mbti.csv', index_col=None) \n",
    "# df = pd.read_excel(open('mbti.xlsx', 'rb'),sheet_name='mbti') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "b6nsfxzq8s2A",
    "outputId": "b202d61a-b5be-4971-e5b6-3631bbe8320e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "df[\"type\"].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBfKqZJP9Wig",
    "outputId": "db785f16-eb7f-4067-f4e9-e183b6980753"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|')\n",
    "URL_RE = re.compile('(\\w+:\\/\\/\\S+)|^rt|http.+?')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = text.replace(\"|||\",\" \")\n",
    "    # text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
    "    # text = BAD_SYMBOLS_RE.sub('', text) \n",
    "    # text = URL_RE.sub('urladd',text)\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "dIhp9iUnBMCy",
    "outputId": "3421ba3e-9bf7-4802-e088-19d60cf84bc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...\n",
       "1     ENTP  finding lack posts alarming sex boring positio...\n",
       "2     INTP  good one course say know blessing curse absolu...\n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...\n",
       "4     ENTJ  fired another silly misconception approaching ...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...\n",
       "8671  ENFP  thread already exists someplace else heck dele...\n",
       "8672  INTP  many questions things would take purple pill p...\n",
       "8673  INFP  conflicted right comes wanting children honest...\n",
       "8674  INFP  long since personalitycafe although seem chang...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['posts'] = df['posts'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "R5l7DR1hBR3B",
    "outputId": "e07a8fa8-91b7-463e-cfef-574e3379aa3e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    8675.000000\n",
       "mean     4105.071931\n",
       "std       981.542474\n",
       "min         5.000000\n",
       "25%      3554.000000\n",
       "50%      4273.000000\n",
       "75%      4824.000000\n",
       "max      6574.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_len = [len(x) for x in df.posts]\n",
    "pd.Series(posts_len).hist()\n",
    "plt.show()\n",
    "pd.Series(posts_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.1 MB 9.6 MB/s eta 0:00:01              | 706 kB 9.6 MB/s eta 0:00:03MB/s eta 0:00:01â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 19.2 MB 9.6 MB/s eta 0:00:01ï¿½â–ˆâ–ˆâ–‹| 23.7 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from gensim) (0.7)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.6/site-packages (from gensim) (1.18.5)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.1.2 smart-open-5.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1tgMddzXIM9h"
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "def label_sentences(corpus, label_type):\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "n17PdaXiIRb9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.posts, df[\"type\"], random_state=10, \n",
    "                                                    test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7hzlJ0gIxy2",
    "outputId": "1804be55-e233-46a2-e33e-7eff3b5565a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2490798.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import doc2vec\n",
    "from tqdm import tqdm\n",
    "vector_size = 300\n",
    "model_dbow = doc2vec.Doc2Vec(dm=0, vector_size=vector_size, negative=5, min_count=1, alpha=0.065, \n",
    "                     min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksTIT_meJYzT",
    "outputId": "e704b06b-f55b-43ec-e1ea-3fd686ba62e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3023314.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2828481.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3448870.82it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 1785620.42it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3481208.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2118150.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2096064.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 1942222.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3488216.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 1512851.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3389435.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 1711135.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3318339.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3212288.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 1653439.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3433898.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2122722.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3396395.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2040237.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3458377.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3544626.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2549795.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2051510.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3413922.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3478213.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 2716964.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3438441.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3365607.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 1912514.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8675/8675 [00:00<00:00, 3472238.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import utils\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), \n",
    "                     total_examples=len(all_data), \n",
    "                     epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "H7661GHegSoT"
   },
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_9CAOWIUJiQq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), vector_size, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), vector_size, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czQdi-9ZJ5U7",
    "outputId": "f3b71894-243c-440c-a90c-103759a1de58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5816365731847868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.28      0.23      0.26        47\n",
      "        ENFP       0.54      0.64      0.59       193\n",
      "        ENTJ       0.42      0.34      0.38        83\n",
      "        ENTP       0.50      0.58      0.54       190\n",
      "        ESFJ       1.00      0.07      0.12        15\n",
      "        ESFP       0.17      0.07      0.10        15\n",
      "        ESTJ       0.00      0.00      0.00        14\n",
      "        ESTP       0.64      0.27      0.38        26\n",
      "        INFJ       0.58      0.67      0.62       435\n",
      "        INFP       0.65      0.72      0.69       559\n",
      "        INTJ       0.58      0.58      0.58       337\n",
      "        INTP       0.60      0.65      0.62       379\n",
      "        ISFJ       0.71      0.32      0.44        47\n",
      "        ISFP       0.47      0.26      0.34        88\n",
      "        ISTJ       0.54      0.32      0.40        60\n",
      "        ISTP       0.65      0.34      0.45       115\n",
      "\n",
      "    accuracy                           0.58      2603\n",
      "   macro avg       0.52      0.38      0.41      2603\n",
      "weighted avg       0.58      0.58      0.57      2603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "model = SVC(C=10, gamma='auto', kernel='rbf')\n",
    "model.fit(train_vectors_dbow, y_train)\n",
    "y_pred = model.predict(test_vectors_dbow)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpKUgg82T0p3"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmoW3n231Ush"
   },
   "source": [
    "https://www.kaggle.com/arunmohan003/sentiment-analysis-using-lstm-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "c8a7j2RETzWu",
    "outputId": "d1e0222e-6722-4703-d16a-f12ded3811dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mbti.csv', index_col=None) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npL8R8KST_H6",
    "outputId": "bf1c8bfc-4919-4ec0-f4c8-7edb27af2565"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|')\n",
    "URL_RE = re.compile('(\\w+:\\/\\/\\S+)|^rt|http.+?')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = text.replace(\"|||\",\" \")\n",
    "    # text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
    "    # text = BAD_SYMBOLS_RE.sub('', text) \n",
    "    # text = URL_RE.sub('urladd',text)\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "dVdKDm6KUE-L",
    "outputId": "36acd9e7-329d-468a-f8c6-0c55b2670635"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...\n",
       "1     ENTP  finding lack posts alarming sex boring positio...\n",
       "2     INTP  good one course say know blessing curse absolu...\n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...\n",
       "4     ENTJ  fired another silly misconception approaching ...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...\n",
       "8671  ENFP  thread already exists someplace else heck dele...\n",
       "8672  INTP  many questions things would take purple pill p...\n",
       "8673  INFP  conflicted right comes wanting children honest...\n",
       "8674  INFP  long since personalitycafe although seem chang...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['posts'] = df['posts'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6Ff1zv5DyJLu"
   },
   "outputs": [],
   "source": [
    "def clean_label(label):\n",
    "  if label==\"ENFJ\":\n",
    "    return 0\n",
    "  elif label==\"ENFP\":\n",
    "    return 1\n",
    "  elif label==\"ENTJ\":\n",
    "    return 2\n",
    "  elif label==\"ENTP\":\n",
    "    return 3\n",
    "  elif label==\"ESFJ\":\n",
    "    return 4\n",
    "  elif label==\"ESFP\":\n",
    "    return 5\n",
    "  elif label==\"ESTJ\":\n",
    "    return 6 \n",
    "  elif label==\"ESTP\":\n",
    "    return 7\n",
    "  elif label==\"ISFP\":\n",
    "    return 8\n",
    "  elif label==\"INFP\":\n",
    "    return 9\n",
    "  elif label==\"INTJ\":\n",
    "    return 10\n",
    "  elif label==\"INTP\":\n",
    "    return 11\n",
    "  elif label==\"ISFJ\":\n",
    "    return 12\n",
    "  elif label==\"ISFP\":\n",
    "    return 13\n",
    "  elif label==\"ISTJ\":\n",
    "    return 14\n",
    "  elif label==\"ISTP\":\n",
    "    return 15\n",
    "  elif label==\"INFJ\":\n",
    "    return 16\n",
    "  else:\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkSgkjkDyNPA",
    "outputId": "df257143-9250-4ca2-c0eb-f6a0fd1837fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       16\n",
       "1        3\n",
       "2       11\n",
       "3       10\n",
       "4        2\n",
       "        ..\n",
       "8670     8\n",
       "8671     1\n",
       "8672    11\n",
       "8673     9\n",
       "8674     9\n",
       "Name: type, Length: 8675, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'] = df['type'].apply(clean_label)\n",
    "df['type'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OQ9BE1sT1WFp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"posts\"], df[\"type\"], random_state=10, \n",
    "                                                    test_size=0.2, stratify = df[\"type\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tockenize(x_train,y_train,x_test,y_test):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.split():\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of most common words (2000) \n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:2000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[word] for word in sent.split() \n",
    "                                     if word in onehot_dict.keys()])\n",
    "    for sent in x_test:\n",
    "            final_list_test.append([onehot_dict[word] for word in sent.split() \n",
    "                                    if word in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [label for label in y_train]  \n",
    "    encoded_test = [label for label in y_test] \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 2000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    6940.000000\n",
       "mean      469.041643\n",
       "std       120.767994\n",
       "min         2.000000\n",
       "25%       397.000000\n",
       "50%       488.000000\n",
       "75%       556.000000\n",
       "max       797.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_len = [len(i) for i in x_train]\n",
    "pd.Series(post_len).hist()\n",
    "plt.show()\n",
    "pd.Series(post_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    length = []\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for index, post in enumerate(sentences):\n",
    "        if len(post) != 0:\n",
    "            length.append(len(post))\n",
    "            features[index, -len(post):] = np.array(post)[:seq_len]\n",
    "    return features,np.array(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "seq_len = 500\n",
    "x_train_pad, x_train_length = padding_(x_train,seq_len)\n",
    "x_test_pad, x_test_length = padding_(x_test,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  50    4   94 ...  628   12   74]\n",
      " [   0    0    0 ...   12 1588   48]\n",
      " [ 461  289   11 ...  839  568  570]\n",
      " ...\n",
      " [   0    0    0 ...  460  792 1189]\n",
      " [  35  496  126 ...    3  176    3]\n",
      " [   0    0    0 ...  100  557 1662]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    offsets = [0]\n",
    "    for (_post, _label, _length) in batch:\n",
    "#         print(\"label: \",_label)\n",
    "#         print(\"text: \",_post)\n",
    "#         print(\"length: \",_length)\n",
    "        label_list.append(_label)\n",
    "        text_list.append(_post)\n",
    "        lengths.append(_length)\n",
    "        offsets.append(seq_len)\n",
    "    # label must be in the same size as target\n",
    "    label_list = torch.tensor(label_list,dtype=torch.float).cumsum(dim=0)\n",
    "    lengths = torch.tensor(lengths).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "#     print(\"text list size: \",text_list.size())\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    return text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad).to(device), torch.from_numpy(y_train).to(device),torch.from_numpy(x_train_length).to(device))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test_pad).to(device), torch.from_numpy(y_test).to(device),torch.from_numpy(x_test_length).to(device))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim):\n",
    "        super().__init__()\n",
    "        # embeddingbag outputs the average of all the words in a sentence\n",
    "        self.embedding = nn.Embedding(len(vocab)+1, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, 1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize network parameters \n",
    "        \"\"\"\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        offsets =  [i for i in range()]\n",
    "        embedded = self.embedding(text) # (batch_size, sent_len, emb_size)\n",
    "        embedded = embedded.sum(dim = 1) / lengths[:, None] # (add one axis)\n",
    "        return torch.sigmoid(self.fc(embedded))\n",
    "\n",
    "class LSTMcustom(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim):\n",
    "        super().__init__()\n",
    "        self.sent_len = len(vocab)+1\n",
    "        self.embed_dim = embed_dim\n",
    "        # embeddingbag outputs the average of all the words in a sentence\n",
    "        self.embedding = nn.Embedding(self.sent_len, embed_dim)\n",
    "        # Initialize LSTM model. The arguments are in this order input_dim, hidden_dim, n_layers\n",
    "        self.lstm = nn.LSTM(embed_dim, 256, 1, bidirectional=False, batch_first = True)\n",
    "        \n",
    "        # # Q1: What should be the input dimension of this linear layer?\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "        # test accuracy: 63.93%\n",
    "        \n",
    "    def forward(self, text, lengths):\n",
    "        embedded = self.embedding(text) # (batch_size, sent_len, emb_size)\n",
    "#         embedded = embedded.view(len(embedded), 1, -1)\n",
    "        embedded = embedded.view(len(lengths),500, self.embed_dim)\n",
    "        lstm_out,_ = self.lstm(embedded) # lstm_out is a 3d tensor (batch_size, sent_len, output_size). If you have a bidirectional LSTM, the outputsize will be 2*output_size\n",
    "        \n",
    "#         # Q3: Select the hidden output of the last element in the sequence. Hint: Remember that you padded the sequence and you already know the length of the sequence.\n",
    "#         batch_size = lstm_out.size()[0]\n",
    "#         last_indices = []\n",
    "#         for length in lengths:\n",
    "#             last_indices.append(int(length)-1)\n",
    "#         last_indices = torch.LongTensor(last_indices)\n",
    "#         rows = torch.arange(0, batch_size).long()\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "#         lstm_out_temp = []\n",
    "#         for index,length in enumerate(lengths):\n",
    "#             lstm_out_temp.append(lstm_out[index,int(length)-1,:])\n",
    "#         lstm_out = torch.stack(lstm_out_temp)\n",
    "        return torch.sigmoid(self.fc(lstm_out))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 50\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (text, label, lengths) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        predicted_label = model(text, lengths)\n",
    "        # calculate loss and backpropagate to model paramters\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        # update parameters by stepping the optimizer\n",
    "        optimizer.step()\n",
    "        total_acc += ((predicted_label > 0.5) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (text, label, lengths) in enumerate(dataloader):\n",
    "            predicted_label = model(text, lengths)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  347 batches | accuracy    0.026\n",
      "| epoch   1 |   100/  347 batches | accuracy    0.023\n",
      "| epoch   1 |   150/  347 batches | accuracy    0.050\n",
      "| epoch   1 |   200/  347 batches | accuracy    0.097\n",
      "| epoch   1 |   250/  347 batches | accuracy    0.044\n",
      "| epoch   1 |   300/  347 batches | accuracy    0.014\n",
      "| epoch   2 |    50/  347 batches | accuracy    0.032\n",
      "| epoch   2 |   100/  347 batches | accuracy    0.066\n",
      "| epoch   2 |   150/  347 batches | accuracy    0.068\n",
      "| epoch   2 |   200/  347 batches | accuracy    0.016\n",
      "| epoch   2 |   250/  347 batches | accuracy    0.009\n",
      "| epoch   2 |   300/  347 batches | accuracy    0.023\n",
      "| epoch   3 |    50/  347 batches | accuracy    0.032\n",
      "| epoch   3 |   100/  347 batches | accuracy    0.064\n",
      "| epoch   3 |   150/  347 batches | accuracy    0.062\n",
      "| epoch   3 |   200/  347 batches | accuracy    0.033\n",
      "| epoch   3 |   250/  347 batches | accuracy    0.067\n",
      "| epoch   3 |   300/  347 batches | accuracy    0.087\n",
      "| epoch   4 |    50/  347 batches | accuracy    0.092\n",
      "| epoch   4 |   100/  347 batches | accuracy    0.106\n",
      "| epoch   4 |   150/  347 batches | accuracy    0.056\n",
      "| epoch   4 |   200/  347 batches | accuracy    0.092\n",
      "| epoch   4 |   250/  347 batches | accuracy    0.126\n",
      "| epoch   4 |   300/  347 batches | accuracy    0.070\n",
      "| epoch   5 |    50/  347 batches | accuracy    0.036\n",
      "| epoch   5 |   100/  347 batches | accuracy    0.110\n",
      "| epoch   5 |   150/  347 batches | accuracy    0.078\n",
      "| epoch   5 |   200/  347 batches | accuracy    0.053\n",
      "| epoch   5 |   250/  347 batches | accuracy    0.096\n",
      "| epoch   5 |   300/  347 batches | accuracy    0.018\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 5 # epoch\n",
    "\n",
    "model = LSTMcustom(vocab=vocab, embed_dim=100).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "total_accu = None\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy  0.00115%\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(test_loader)\n",
    "print('test accuracy {:8.5f}%'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://brandonrose.org/clustering\n",
    "\n",
    "https://www.youtube.com/watch?v=ORpDAUQUnkU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mbti.csv', index_col=None) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 2 columns):\n",
      "type     8675 non-null object\n",
      "posts    8675 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 135.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|')\n",
    "URL_RE = re.compile('(\\w+:\\/\\/\\S+)|^rt|http.+?')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = text.replace(\"|||\",\"\\n\")\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...\n",
       "1     ENTP  finding lack posts alarming sex boring positio...\n",
       "2     INTP  good one course say know blessing curse absolu...\n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...\n",
       "4     ENTJ  fired another silly misconception approaching ...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...\n",
       "8671  ENFP  thread already exists someplace else heck dele...\n",
       "8672  INTP  many questions things would take purple pill p...\n",
       "8673  INFP  conflicted right comes wanting children honest...\n",
       "8674  INFP  long since personalitycafe although seem chang...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['posts'] = df['posts'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>EI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts EI\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...  I\n",
       "1     ENTP  finding lack posts alarming sex boring positio...  E\n",
       "2     INTP  good one course say know blessing curse absolu...  I\n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...  I\n",
       "4     ENTJ  fired another silly misconception approaching ...  E\n",
       "...    ...                                                ... ..\n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...  I\n",
       "8671  ENFP  thread already exists someplace else heck dele...  E\n",
       "8672  INTP  many questions things would take purple pill p...  I\n",
       "8673  INFP  conflicted right comes wanting children honest...  I\n",
       "8674  INFP  long since personalitycafe although seem chang...  I\n",
       "\n",
       "[8675 rows x 3 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"EI\"] = [row[\"type\"][0] for _,row in df.iterrows()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>EI</th>\n",
       "      <th>NS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts EI NS\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...  I  N\n",
       "1     ENTP  finding lack posts alarming sex boring positio...  E  N\n",
       "2     INTP  good one course say know blessing curse absolu...  I  N\n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...  I  N\n",
       "4     ENTJ  fired another silly misconception approaching ...  E  N\n",
       "...    ...                                                ... .. ..\n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...  I  S\n",
       "8671  ENFP  thread already exists someplace else heck dele...  E  N\n",
       "8672  INTP  many questions things would take purple pill p...  I  N\n",
       "8673  INFP  conflicted right comes wanting children honest...  I  N\n",
       "8674  INFP  long since personalitycafe although seem chang...  I  N\n",
       "\n",
       "[8675 rows x 4 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NS\"] = [row[\"type\"][1] for _,row in df.iterrows()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>EI</th>\n",
       "      <th>NS</th>\n",
       "      <th>FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts EI NS FT\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...  I  N  F\n",
       "1     ENTP  finding lack posts alarming sex boring positio...  E  N  T\n",
       "2     INTP  good one course say know blessing curse absolu...  I  N  T\n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...  I  N  T\n",
       "4     ENTJ  fired another silly misconception approaching ...  E  N  T\n",
       "...    ...                                                ... .. .. ..\n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...  I  S  F\n",
       "8671  ENFP  thread already exists someplace else heck dele...  E  N  F\n",
       "8672  INTP  many questions things would take purple pill p...  I  N  T\n",
       "8673  INFP  conflicted right comes wanting children honest...  I  N  F\n",
       "8674  INFP  long since personalitycafe although seem chang...  I  N  F\n",
       "\n",
       "[8675 rows x 5 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"FT\"] = [row[\"type\"][2] for _,row in df.iterrows()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>EI</th>\n",
       "      <th>NS</th>\n",
       "      <th>FT</th>\n",
       "      <th>PJ</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>ixfp always think cats fi doms reason especial...</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts EI NS FT PJ  \\\n",
       "0     INFJ  enfp intj moments sportscenter top ten plays p...  I  N  F  J   \n",
       "1     ENTP  finding lack posts alarming sex boring positio...  E  N  T  P   \n",
       "2     INTP  good one course say know blessing curse absolu...  I  N  T  P   \n",
       "3     INTJ  dear intp enjoyed conversation day esoteric ga...  I  N  T  J   \n",
       "4     ENTJ  fired another silly misconception approaching ...  E  N  T  J   \n",
       "...    ...                                                ... .. .. .. ..   \n",
       "8670  ISFP  ixfp always think cats fi doms reason especial...  I  S  F  P   \n",
       "8671  ENFP  thread already exists someplace else heck dele...  E  N  F  P   \n",
       "8672  INTP  many questions things would take purple pill p...  I  N  T  P   \n",
       "8673  INFP  conflicted right comes wanting children honest...  I  N  F  P   \n",
       "8674  INFP  long since personalitycafe although seem chang...  I  N  F  P   \n",
       "\n",
       "      cluster  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "8670        0  \n",
       "8671        0  \n",
       "8672        0  \n",
       "8673        0  \n",
       "8674        0  \n",
       "\n",
       "[8675 rows x 7 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PJ\"] = [row[\"type\"][3] for _,row in df.iterrows()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df[\"posts\"].values.astype(\"U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "features = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=2, n_init=1)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2\n",
    "model = KMeans(n_clusters=k,init=\"k-means++\",max_iter=100,n_init=1)\n",
    "model.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>EI</th>\n",
       "      <th>NS</th>\n",
       "      <th>FT</th>\n",
       "      <th>PJ</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp intj moments sportscenter top ten plays p...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming sex boring positio...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoyed conversation day esoteric ga...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts EI NS FT PJ  \\\n",
       "0  INFJ  enfp intj moments sportscenter top ten plays p...  I  N  F  I   \n",
       "1  ENTP  finding lack posts alarming sex boring positio...  E  N  T  E   \n",
       "2  INTP  good one course say know blessing curse absolu...  I  N  T  I   \n",
       "3  INTJ  dear intp enjoyed conversation day esoteric ga...  I  N  T  I   \n",
       "4  ENTJ  fired another silly misconception approaching ...  E  N  T  E   \n",
       "\n",
       "   cluster  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(column,reverse):\n",
    "    count = 0\n",
    "    if(reverse):\n",
    "        a = column[1]\n",
    "        b = column[0]\n",
    "    else:\n",
    "        a = column[0]\n",
    "        b = column[1]\n",
    "    for i,row in df.iterrows():\n",
    "        if((row[column]==a) and (row.cluster==1)):\n",
    "            count += 1\n",
    "        elif((row[column]==b) and (row.cluster==0)):\n",
    "            count += 1\n",
    "    return count/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(column):\n",
    "    a = calculate_score(column,False)\n",
    "    b = calculate_score(column,True)\n",
    "    if(a>b):\n",
    "        x = column[0]\n",
    "        y = column[1]\n",
    "        score = a\n",
    "    else:\n",
    "        x = column[1]\n",
    "        y = column[0]\n",
    "        score = b\n",
    "    print(f\"accuracy with ({x},{y}) = (1,0): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with (E,I) = (1,0): 0.7636887608069164\n",
      "accuracy with (S,N) = (1,0): 0.8563688760806917\n",
      "accuracy with (T,F) = (1,0): 0.5398270893371758\n",
      "accuracy with (J,P) = (1,0): 0.6026512968299712\n"
     ]
    }
   ],
   "source": [
    "score(\"EI\")\n",
    "score(\"NS\")\n",
    "score(\"FT\")\n",
    "score(\"PJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon Sentiment Analysis (Unsupervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datatattle/lexicon-sentiment-analysis-unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp36-cp36m-manylinux1_x86_64.whl (366 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 366 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from wordcloud) (6.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from wordcloud) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import numpy as np # provides a high-performance multidimensional array and tools for its manipulation\n",
    "import pandas as pd # for data munging, it contains manipulation tools designed to make data analysis fast and easy\n",
    "import re # Regular Expressions - useful for extracting information from text \n",
    "import nltk # Natural Language Tool Kit for symbolic and statistical natural language processing\n",
    "import spacy # processing and understanding large volumes of text\n",
    "import string # String module contains some constants, utility function, and classes for string manipulation\n",
    "import re\n",
    "\n",
    "# For viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mbti.csv', index_col=None) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are primarily 3 ways:\n",
    "# 1) Rule-based methods\n",
    "# 2) Feature-based methods\n",
    "# 3) Embedding-based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125 kB 25.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from vaderSentiment) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->vaderSentiment) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->vaderSentiment) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->vaderSentiment) (2020.4.5.2)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaderSentiment\n",
    "# calling SentimentIntensityAnalyzer object\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [http, www, youtube, com, watch, v, qsXHcwe3kr...\n",
       "1    [I, m, finding, the, lack, of, me, in, these, ...\n",
       "2    [Good, one, _____, https, www, youtube, com, w...\n",
       "3    [Dear, INTP, I, enjoyed, our, conversation, th...\n",
       "4    [You, re, fired, That, s, another, silly, misc...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words_descriptions = df['posts'].apply(tokenizer.tokenize)\n",
    "words_descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11664593 words total, with a vocabulary size of 177653\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in words_descriptions for word in tokens]\n",
    "df['description_lengths']= [len(tokens) for tokens in words_descriptions]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_words), len(VOCAB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 600859),\n",
       " ('to', 301400),\n",
       " ('the', 280633),\n",
       " ('a', 238597),\n",
       " ('and', 230458),\n",
       " ('of', 184180),\n",
       " ('you', 164009),\n",
       " ('it', 150240),\n",
       " ('that', 150141),\n",
       " ('is', 136883),\n",
       " ('in', 123739),\n",
       " ('t', 109686),\n",
       " ('my', 108681),\n",
       " ('s', 106919),\n",
       " ('for', 86608),\n",
       " ('have', 82603),\n",
       " ('with', 81785),\n",
       " ('me', 80864),\n",
       " ('but', 78916),\n",
       " ('m', 77202),\n",
       " ('be', 75138),\n",
       " ('are', 69465),\n",
       " ('like', 66719),\n",
       " ('not', 65549),\n",
       " ('this', 62903),\n",
       " ('on', 61792),\n",
       " ('an', 60526),\n",
       " ('was', 58387),\n",
       " ('as', 55599),\n",
       " ('can', 51402),\n",
       " ('just', 50331),\n",
       " ('or', 50258),\n",
       " ('about', 49597),\n",
       " ('think', 49358),\n",
       " ('so', 48513),\n",
       " ('don', 47185),\n",
       " ('do', 46833),\n",
       " ('people', 44789),\n",
       " ('your', 42245),\n",
       " ('what', 41810),\n",
       " ('at', 39498),\n",
       " ('if', 38816),\n",
       " ('all', 37887),\n",
       " ('know', 36621),\n",
       " ('i', 36119),\n",
       " ('when', 36097),\n",
       " ('they', 35708),\n",
       " ('It', 35612),\n",
       " ('more', 34493),\n",
       " ('really', 34038),\n",
       " ('would', 33929),\n",
       " ('ve', 33667),\n",
       " ('one', 33556),\n",
       " ('out', 30876),\n",
       " ('get', 30147),\n",
       " ('am', 29540),\n",
       " ('from', 28814),\n",
       " ('we', 28700),\n",
       " ('because', 28667),\n",
       " ('The', 28442),\n",
       " ('time', 26901),\n",
       " ('up', 26128),\n",
       " ('com', 25860),\n",
       " ('how', 25794),\n",
       " ('he', 25772),\n",
       " ('some', 25400),\n",
       " ('re', 25175),\n",
       " ('them', 24720),\n",
       " ('very', 24347),\n",
       " ('there', 24061),\n",
       " ('who', 23363),\n",
       " ('You', 23186),\n",
       " ('feel', 23056),\n",
       " ('much', 22790),\n",
       " ('too', 21737),\n",
       " ('been', 21340),\n",
       " ('being', 20859),\n",
       " ('by', 20457),\n",
       " ('things', 19979),\n",
       " ('say', 19977),\n",
       " ('other', 19822),\n",
       " ('way', 19381),\n",
       " ('want', 19171),\n",
       " ('love', 19163),\n",
       " ('watch', 19064),\n",
       " ('something', 18809),\n",
       " ('good', 18782),\n",
       " ('had', 18693),\n",
       " ('see', 18493),\n",
       " ('will', 18307),\n",
       " ('no', 18258),\n",
       " ('www', 18140),\n",
       " ('My', 17901),\n",
       " ('only', 17497),\n",
       " ('http', 17491),\n",
       " ('youtube', 17127),\n",
       " ('v', 17099),\n",
       " ('If', 17083),\n",
       " ('than', 16979),\n",
       " ('has', 16957)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking most common words\n",
    "from collections import Counter\n",
    "count_all_words = Counter(all_words)\n",
    "count_all_words.most_common(100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MBTI personality test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
