{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cds project ML models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "a871dbaf8ba6363035c157814b83ea00ea26824d15029fff46b23e2e4729fcff"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-bNwvsihO0H"
      },
      "source": [
        "import pandas as pd\n",
        "\"\"\"!pip install bs4 \n",
        "!pip install sklearn\n",
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install lxml\"\"\"\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "import lxml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from gensim.models import doc2vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yXqUnaeRhmNu",
        "outputId": "8dbd6273-6155-4bf9-fe77-f63edbd8b4ee"
      },
      "source": [
        "df = pd.read_csv(\"/content/mbti_1.csv\")\n",
        "df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce..."
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fto4LDyVkABC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a822279-a4de-4ed6-fd18-56437ce3ff13"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    \n",
        "    text = text.lower() # lowercase text\n",
        "    \n",
        "    \n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nVWkOQBxlIYY",
        "outputId": "e52cf55e-c6ef-41e8-c24f-b25668637ce9"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"for k in range(0,len(df.index)):\n",
        "  print(k)\n",
        "  print(df[\"posts\"][k])\n",
        "  df[\"posts\"][k] = clean_text(df[\"posts\"][k])\"\"\"\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(clean_text)\n",
        "df"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>http wwwyoutubecom watchvqscwe3krw http 41medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>finding lack posts alarming ex boring position...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>ood one _____ https wwwyoutubecom watchvfibolw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>ear enjoyed conversation day soteric gabbing n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>oure fired hats another silly misconception ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>https wwwyoutubecom watchvt8ed_h908 x always t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8671</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>oif thread already exists someplace else http ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8672</th>\n",
              "      <td>INTP</td>\n",
              "      <td>many questions things would take purple pill i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8673</th>\n",
              "      <td>INFP</td>\n",
              "      <td>conflicted right comes wanting children honest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>INFP</td>\n",
              "      <td>long since personalitycafe although doesnt see...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8675 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                              posts\n",
              "0     INFJ  http wwwyoutubecom watchvqscwe3krw http 41medi...\n",
              "1     ENTP  finding lack posts alarming ex boring position...\n",
              "2     INTP  ood one _____ https wwwyoutubecom watchvfibolw...\n",
              "3     INTJ  ear enjoyed conversation day soteric gabbing n...\n",
              "4     ENTJ  oure fired hats another silly misconception ha...\n",
              "...    ...                                                ...\n",
              "8670  ISFP  https wwwyoutubecom watchvt8ed_h908 x always t...\n",
              "8671  ENFP  oif thread already exists someplace else http ...\n",
              "8672  INTP  many questions things would take purple pill i...\n",
              "8673  INFP  conflicted right comes wanting children honest...\n",
              "8674  INFP  long since personalitycafe although doesnt see...\n",
              "\n",
              "[8675 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JblfFzUOlawf"
      },
      "source": [
        "x= df[\"posts\"]\n",
        "y=df[\"type\"]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3mcAhdBlwXm"
      },
      "source": [
        "def label_sentences(corpus, label_type):\n",
        "    \"\"\"\n",
        "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
        "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
        "    a dummy index of the post.\n",
        "    \"\"\"\n",
        "    labeled = []\n",
        "    for i, v in enumerate(corpus):\n",
        "        label = label_type + '_' + str(i)\n",
        "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
        "    return labeled"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNx_jwBdl3zy"
      },
      "source": [
        "X_train = label_sentences(x_train, 'Train')\n",
        "X_test = label_sentences(x_test, 'Test')\n",
        "all_data = X_train + X_test\n",
        "#all_data[0:5]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVCYGpApl9tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2d04c2-6d55-4069-fd4b-7f8d91ea5106"
      },
      "source": [
        "model_dbow = doc2vec.Doc2Vec(dm=0, vector_size=100, negative=5, min_count=1, alpha=0.065, \n",
        "                     min_alpha=0.065)\n",
        "model_dbow.build_vocab([x for x in tqdm(all_data)])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8675/8675 [00:00<00:00, 1499076.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64pGQyzmLfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe05444b-ee14-4073-8853-a6d35a138344"
      },
      "source": [
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), \n",
        "                     total_examples=len(all_data), \n",
        "                     epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8675/8675 [00:00<00:00, 1228578.71it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2969040.16it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1179244.44it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2379075.93it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2447735.43it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1206098.75it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1176384.97it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2588800.23it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 3092960.49it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2967345.23it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2843957.10it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2634346.02it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2571237.88it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1201558.26it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2607911.93it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1026681.35it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1001667.92it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2493529.82it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2782836.50it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1219560.49it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 1987414.64it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2659570.73it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2537703.11it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2775618.83it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2384845.46it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2944055.93it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2555885.59it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2997412.24it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2704242.82it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2640463.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6sdsHZRrmP5"
      },
      "source": [
        "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
        "    \"\"\"\n",
        "    Get vectors from trained doc2vec model\n",
        "    :param doc2vec_model: Trained Doc2Vec model\n",
        "    :param corpus_size: Size of the data\n",
        "    :param vectors_size: Size of the embedding vectors\n",
        "    :param vectors_type: Training or Testing vectors\n",
        "    :return: list of vectors\n",
        "    \"\"\"\n",
        "    vectors = np.zeros((corpus_size, vectors_size))\n",
        "    for i in range(0, corpus_size):\n",
        "        prefix = vectors_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoGVExIDrpiL"
      },
      "source": [
        "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 100, 'Train')\n",
        "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 100, 'Test')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAd3MgVrvGg"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "\n",
        "def nb_model(x_train,x_test,y_train,y_test):\n",
        "  \n",
        "\n",
        "  classifier = GaussianNB()  \n",
        "  classifier.fit(x_train, y_train) \n",
        "  y_pred = classifier.predict(x_test)\n",
        "\n",
        " \n",
        "  return 'accuracy %s' % accuracy_score(y_pred, y_test)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj7kQM_tsw9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ccf4bb-732b-44ce-ad49-7c970e430079"
      },
      "source": [
        "print(nb_model(train_vectors_dbow,test_vectors_dbow,y_train,y_test))\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.35266999615827893\n"
          ]
        }
      ]
    }
  ]
}