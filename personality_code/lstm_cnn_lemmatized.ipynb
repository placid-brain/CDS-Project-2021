{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0-ORnNrVgoe"
   },
   "source": [
    "## Balance data\n",
    "\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzly-KMSVgoh"
   },
   "source": [
    "## SJ's Code\n",
    "\n",
    "https://github.com/declare-lab/conv-emotion/blob/0c9dcb9cc5234a7ca8cf6af81aabe28ef3814d0e/DialogueRNN/train_E2E.py#L81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gM4cuug2Vgoh"
   },
   "source": [
    "### load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "whBeBw94Vgoi",
    "outputId": "e7387658-ffa8-4484-b57f-0f474bea9ef9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts_length</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>304</td>\n",
       "      <td>enfp intj moments sportscenter top ten play pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>554</td>\n",
       "      <td>find lack post alarm sex bore position often e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>427</td>\n",
       "      <td>good one course say know bless curse absolutel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>521</td>\n",
       "      <td>dear intp enjoy conversation day esoteric gabb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>477</td>\n",
       "      <td>fire another silly misconception approach logi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  posts_length                                         lemmatized\n",
       "0  INFJ           304  enfp intj moments sportscenter top ten play pr...\n",
       "1  ENTP           554  find lack post alarm sex bore position often e...\n",
       "2  INTP           427  good one course say know bless curse absolutel...\n",
       "3  INTJ           521  dear intp enjoy conversation day esoteric gabb...\n",
       "4  ENTJ           477  fire another silly misconception approach logi..."
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('mbti_rm_stop_lemmatized.csv', index_col=None) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTERk6DAVgok"
   },
   "source": [
    "### encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "id": "KOEKiuHHVgok"
   },
   "outputs": [],
   "source": [
    "int2mbti={0:'ENFJ',1:'ENFP',2:'ENTJ',3:'ENTP',4:'ESFJ',5:'ESFP',6:'ESTJ',7:'ESTP',8:'INFJ',9:'INFP',10:'INTJ',11:'INTP',12:'ISFJ',13:'ISFP',14:'ISTJ',15:'ISTP'}\n",
    "mbti2int={'ENFJ':0,'ENFP':1,'ENTJ':2,'ENTP':3,'ESFJ':4,'ESFP':5,'ESTJ':6,'ESTP':7,'INFJ':8,'INFP':9,'INTJ':10,'INTP':11,'ISFJ':12,'ISFP':13,'ISTJ':14,'ISTP':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk4TsUBYVgok",
    "outputId": "df80d3ec-41f9-47e7-fb84-d86a3d6f3974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 10, 1, 15, 11, 13, 9, 14, 3, 9, 8, 9, 10, 9, 3, 11, 9, 8, 3, 8, 8, 9, 11, 9, 9, 8, 15, 12, 9, 14, 8, 8, 10, 4, 1, 9, 3, 10, 11, 11, 3, 10, 3, 10, 8, 13, 1, 11, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "labels = df.type.tolist()\n",
    "labels = [mbti2int.get(label) for label in labels]\n",
    "print(labels[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqwhztRQVgol"
   },
   "source": [
    "### clean posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "euKkHNpGXFWw",
    "outputId": "ed516ae6-6f5b-4ab9-addd-3630764abc83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in /opt/conda/lib/python3.6/site-packages (2.6.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vjp0Z2JqVgol",
    "outputId": "4a812a7c-3038-429d-8735-25a713d067c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from autocorrect import Speller \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class data_preprocessing():\n",
    "    \n",
    "    def remove_links(text):\n",
    "        remove_https = re.sub(r'http\\S+', '', text)\n",
    "        remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n",
    "        return remove_com\n",
    "    \n",
    "    def remove_digits(text):\n",
    "        return re.sub(r'\\d+', ' ', text)\n",
    "    \n",
    "    def remove_symbols(text):\n",
    "        REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "        BAD_SYMBOLS_RE = re.compile('(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)')\n",
    "        t = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        t = BAD_SYMBOLS_RE.sub(' ', t)\n",
    "        return t\n",
    "    \n",
    "    def deduce_repeated_characters(text):\n",
    "        Pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
    "        Formatted_text = Pattern_alpha.sub(r\"\\1\\1\", text) \n",
    "        Pattern_Punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
    "        Combined_Formatted = Pattern_Punct.sub(r'\\1', Formatted_text)\n",
    "        Final_Formatted = re.sub(' {2,}',' ', Combined_Formatted)\n",
    "        return Final_Formatted\n",
    "    \n",
    "    def remove_special_characters(text):\n",
    "        return re.sub(r\"[^a-zA-Z0-9:$-,%.?!]+\", ' ', text)\n",
    "    \n",
    "    def spelling_correction(text):\n",
    "        spell = Speller(lang='en')\n",
    "        Corrected_text = spell(text)\n",
    "        return Corrected_text\n",
    "    \n",
    "    def lemmatization(text):\n",
    "        w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        lemma = [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "5vRxZq8gVgom"
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(t):\n",
    "    t = t.lower()\n",
    "    t = t.replace(\"|||\",\" \")   \n",
    "    t = data_preprocessing.remove_links(t)\n",
    "    t = data_preprocessing.remove_digits(t)\n",
    "    t = data_preprocessing.remove_symbols(t)\n",
    "    t = data_preprocessing.deduce_repeated_characters(t)\n",
    "    t = data_preprocessing.remove_special_characters(t)\n",
    "#         t = data_preprocessing.spelling_correction(t)\n",
    "    t = data_preprocessing.lemmatization(t)\n",
    "    t = ' '.join(word for word in t.split() if word not in STOPWORDS) \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNVRUmSOVgom",
    "outputId": "a63720cd-6f80-4b9e-9081-16458f2723d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enfp intj moments sportscenter top ten play prank life change experience life repeat today may perc experience immerse last thing infj friend post facebook commit suicide next day rest peace hello enfj sorry hear distress natural relationship perfection time every moment existence try figure hard time time growth welcome stuff game set match prozac wellbrutin least thirty minutes move legs mean move sit desk chair weed moderation maybe try edibles healthy alternative basically come three items determine type whichever type want would likely use give type cognitive function whatnot leave things moderation sims indeed video game good one note good one somewhat subjective completely promote death give sim dear enfp favorite video game grow current favorite video game cool appear late sad someone everyone wait think confidence good thing cherish time solitude revel within inner world whereas time workin enjoy time worry people always around yo entp ladies complimentary personality well hey main social outlet xbox live conversations even verbally fatigue quickly really dig part ban thread require get high backyard roast eat marshmellows backyard converse something intellectual follow massage kiss ban many sentence could think ban watch movies corner dunces ban health class clearly teach nothing peer pressure ban whole host reason two baby deer leave right munch beetle middle use blood two cavemen diary today late happen designate cave diary wall see pokemon world infj society everyone become optimist artists artists draw idea count form something like signature welcome robot rank person down self esteem cuz avid signature artist like proud ban take room bed ya get ta learn share roach ban much thunder grumble kind storm yep ahh old high school music hear age fail public speak class years ago sort learn could good position big part failure overload like person mentality confirm intj way move denver area start new life \n"
     ]
    }
   ],
   "source": [
    "posts = df.lemmatized.tolist()\n",
    "# posts = [clean_text(post) for post in posts]\n",
    "print(posts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwhmFmdTVgon"
   },
   "source": [
    "### create vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "id": "4-F31ZAMVgon"
   },
   "outputs": [],
   "source": [
    "# Count total words\n",
    "from collections import Counter\n",
    "\n",
    "word_count=Counter()\n",
    "for post in posts:\n",
    "    if isinstance(post, str):\n",
    "        word_count.update(post.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JB7r2b4Vgoo",
    "outputId": "b6de5268-53b7-4200-b422-85a604138f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84822\n",
      "1946\n"
     ]
    }
   ],
   "source": [
    "# Size of the vocabulary available to the RNN\n",
    "vocab_len=len(word_count)\n",
    "print(vocab_len)\n",
    "\n",
    "print(len(posts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Cag_e7yVgoo"
   },
   "source": [
    "### encode posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yruTbfJGVgop",
    "outputId": "27f909eb-1438-4663-9f8e-7dff644f6ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "# Create a look up table \n",
    "vocab = sorted(word_count, key=word_count.get, reverse=True)\n",
    "# Create your dictionary that maps vocab words to integers here\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "posts_ints=[]\n",
    "for post in posts:\n",
    "    if isinstance(post, str):\n",
    "        posts_ints.append([vocab_to_int[word] for word in post.split()])\n",
    "\n",
    "# print(posts_ints[0])\n",
    "print(len(posts_ints[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsBMlGoIVgop",
    "outputId": "8807b7b4-e165-4774-e3c5-c7bb4b2efe5e"
   },
   "outputs": [],
   "source": [
    "import torchtext as text\n",
    "\n",
    "# load glove embeddings\n",
    "vec = text.vocab.GloVe(name='6B', dim=50)\n",
    "# create the embedding matrix, a torch tensor in the shape (num_words+1, embedding_dim)\n",
    "word_emb = vec.get_vecs_by_tokens(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzHMdaAoVgop"
   },
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5P7oxi5Vgoq",
    "outputId": "e082f2d1-b827-4ba6-8369-7abee59e9d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 0\n",
      "Maximum review length: 6216\n",
      "Minimum review length: 33\n",
      "[[    0     0     0 ...    66   119    38]\n",
      " [   21   424    45 ...   602   377  1030]\n",
      " [    0     0     0 ...  1622  1140   200]\n",
      " ...\n",
      " [  147   563  2826 ...   119     1   432]\n",
      " [    0     0     0 ... 13468  6006    92]\n",
      " [  873    51   112 ...  1509  8225    33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "posts_lens = Counter([len(x) for x in posts])\n",
    "print(\"Zero-length reviews: {}\".format(posts_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(posts_lens)))\n",
    "print(\"Minimum review length: {}\".format(min(posts_lens)))\n",
    "\n",
    "\n",
    "seq_len = 500\n",
    "features=np.zeros((len(posts_ints),seq_len),dtype=int)\n",
    "for i, row in enumerate(posts_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pntpEmVYVgoq",
    "outputId": "c9ede30f-c0ad-40ed-cfd1-61ea6984b646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8674\n",
      "8674\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyseCVxNVgor"
   },
   "source": [
    "### create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "JiufnWAmY3zY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCGewCsiVgor",
    "outputId": "9278ef04-b3df-4df9-b96e-80c4cac8e359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deive type:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vocab_size = 40000\n",
    "seq_len = 500\n",
    "num_labels = 16\n",
    "EMBEDDING_DIM=50\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "print(\"deive type: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJ7gVz9TVgos",
    "outputId": "4d20347f-06de-42b6-fc8c-aa518d224a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6939 6939\n",
      "867 867\n",
      "868 868\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=50, \n",
    "                                                    test_size=0.2, stratify = labels )\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, random_state=0, \n",
    "                                                    test_size=0.5, stratify = y_test )\n",
    "\n",
    "print(len(x_train),len(y_train))\n",
    "print(len(x_test),len(y_test))\n",
    "print(len(x_val),len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "id": "wtqLMdzkVgos"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_post, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "        text_list.append(_post)\n",
    "    # label must be in the same size as target\n",
    "    label_list = torch.tensor(label_list)\n",
    "    text_list = torch.stack(text_list)\n",
    "    return text_list.to(device), label_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "id": "hr5z3KUuVgos"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# # create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train).to(device), torch.tensor(y_train).to(device))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test).to(device),torch.tensor(y_test).to(device))\n",
    "val_data = TensorDataset(torch.from_numpy(x_val).to(device),torch.tensor(y_val).to(device))\n",
    "\n",
    "# # dataloaders\n",
    "batch_size = 256\n",
    "\n",
    "# # make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBFUAADsVgos"
   },
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "id": "RkPRDGOIVgos"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "id": "XJ3NLN2DVgos"
   },
   "outputs": [],
   "source": [
    "class SimpleAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.scalar = nn.Linear(self.input_dim,num_labels,bias=False)\n",
    "\n",
    "    def forward(self, M, x=None):\n",
    "        \"\"\"\n",
    "        M -> (seq_len, batch, vector)\n",
    "        x -> dummy argument for the compatibility with MatchingAttention\n",
    "        \"\"\"\n",
    "        scale = self.scalar(M) # seq_len, batch, 1\n",
    "        alpha = F.softmax(scale, dim=0).permute(1,2,0) # batch, 1, seq_len\n",
    "        attn_pool = torch.bmm(alpha, M.transpose(0,1))[:,0,:] # batch, vector\n",
    "\n",
    "        return attn_pool, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "MhHqRM3VVgot"
   },
   "outputs": [],
   "source": [
    "# logistic model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, word_vec, embed_dim):\n",
    "        super().__init__()\n",
    "        # embeddingbag outputs the average of all the words in a sentence\n",
    "        self.embedding = nn.Embedding(*(word_vec.size())).from_pretrained(word_vec, freeze=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_labels)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize network parameters \n",
    "        \"\"\"\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text) # (batch_size, sent_len, emb_size)\n",
    "        embedded = embedded.sum(dim = 1) / lengths[:, None] # (add one axis)\n",
    "        return torch.sigmoid(self.fc(embedded))\n",
    "\n",
    "class LSTMcustom(nn.Module):\n",
    "    def __init__(self, word_vec, embed_dim):\n",
    "        super().__init__()\n",
    "        # embeddingbag outputs the average of all the words in a sentence\n",
    "        self.embedding = nn.Embedding(*(word_vec.size())).from_pretrained(word_vec, freeze=False)\n",
    "        self.cnn = torch.nn.Conv1d(embed_dim,20,2)\n",
    "        self.lstm = nn.LSTM(20, 200, 1, bidirectional=False, batch_first = True)      \n",
    "        self.attention = SimpleAttention(200) \n",
    "        \n",
    "        filter_sizes = [1,2,3,4,5]\n",
    "        num_filters = 100\n",
    "        \n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, 200)) for K in filter_sizes])\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, num_labels)\n",
    "                \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text) # (batch_size, sent_len, emb_size)\n",
    "        # print(\"embedded: \", embedded.size())\n",
    "        \n",
    "        embedded = embedded.permute(0,2,1)\n",
    "        cnn_out = self.cnn(embedded)\n",
    "        # print(\"cnn_out: \", cnn_out.size())\n",
    "        \n",
    "        cnn_out = cnn_out.permute(0,2,1)\n",
    "        lstm_out,_ = self.lstm(cnn_out) # lstm_out is a 3d tensor (batch_size, seq_len, output_size). If you have a bidirectional LSTM, the outputsize will be 2*output_size\n",
    "        # print(\"lstm_out: \", lstm_out.size())\n",
    "#         lstm_out = lstm_out.permute(1,0,2)\n",
    "\n",
    "#         atten_out, alpha = self.attention(lstm_out)       \n",
    "#         print(\"lstm_out: \", lstm_out.size()) \n",
    "        # print(\"atten_out (fc): \",self.fc(atten_out).size())\n",
    "        x = lstm_out.unsqueeze(1)  \n",
    "#         print(\"x dimension: \",x.size())\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
    "#         print(\"x1: \",x )\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
    "#         print(\"x2: \",x )\n",
    "        x = torch.cat(x, 1)\n",
    "#         print(\"x dimension: \",x.size())\n",
    "        x = self.dropout(x)  \n",
    "        logit = self.fc1(x) \n",
    "        \n",
    "        return torch.log_softmax(torch.tanh(logit),0)\n",
    "#         return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "id": "jkcx-phnVgot"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "#     model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 20\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (text, label) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        predicted_label = model(text)\n",
    "        # label = torch.reshape(label,(len(label),1))\n",
    "        # calculate loss and backpropagate to model paramters\n",
    "#         print(\"predicted label size: \",predicted_label.size())\n",
    "#         print(\"label size: \",label.size())\n",
    "        loss = criterion(predicted_label, label)\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        # update parameters by stepping the optimizer\n",
    "        optimizer.step()\n",
    "        predicted_label = torch.argmax(predicted_label,1)\n",
    "        # print(predicted_label)\n",
    "        total_acc += (predicted_label == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f} | loss {:8f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count,loss.item()))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "#             evaluate(val_loader)\n",
    "#             print()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (text, label) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    print('val accuracy {:8.2f} | val loss {:8f}'.format(total_acc/total_count,loss.item()))\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "d2vrnltsVgot"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    20/   28 batches | accuracy    0.077 | loss 2.774629\n",
      "val accuracy     0.13 | val loss 2.771973\n",
      "\n",
      "| epoch   2 |    20/   28 batches | accuracy    0.144 | loss 2.706337\n",
      "val accuracy     0.24 | val loss 2.632073\n",
      "\n",
      "| epoch   3 |    20/   28 batches | accuracy    0.195 | loss 2.576644\n",
      "val accuracy     0.17 | val loss 2.574124\n",
      "\n",
      "| epoch   4 |    20/   28 batches | accuracy    0.199 | loss 2.455653\n",
      "val accuracy     0.20 | val loss 2.533358\n",
      "\n",
      "| epoch   5 |    20/   28 batches | accuracy    0.189 | loss 2.443012\n",
      "val accuracy     0.16 | val loss 2.551710\n",
      "\n",
      "| epoch   6 |    20/   28 batches | accuracy    0.262 | loss 2.294384\n",
      "val accuracy     0.29 | val loss 2.391628\n",
      "\n",
      "| epoch   7 |    20/   28 batches | accuracy    0.321 | loss 2.213099\n",
      "val accuracy     0.30 | val loss 2.432524\n",
      "\n",
      "| epoch   8 |    20/   28 batches | accuracy    0.366 | loss 2.227912\n",
      "val accuracy     0.32 | val loss 2.414725\n",
      "\n",
      "| epoch   9 |    20/   28 batches | accuracy    0.402 | loss 2.025080\n",
      "val accuracy     0.30 | val loss 2.365267\n",
      "\n",
      "| epoch  10 |    20/   28 batches | accuracy    0.459 | loss 1.968761\n",
      "val accuracy     0.29 | val loss 2.418967\n",
      "\n",
      "| epoch  11 |    20/   28 batches | accuracy    0.507 | loss 1.882605\n",
      "val accuracy     0.33 | val loss 2.392956\n",
      "\n",
      "| epoch  12 |    20/   28 batches | accuracy    0.539 | loss 1.890028\n",
      "val accuracy     0.33 | val loss 2.435166\n",
      "\n",
      "| epoch  13 |    20/   28 batches | accuracy    0.566 | loss 1.887512\n",
      "val accuracy     0.34 | val loss 2.374924\n",
      "\n",
      "| epoch  14 |    20/   28 batches | accuracy    0.586 | loss 1.871360\n",
      "val accuracy     0.34 | val loss 2.413692\n",
      "\n",
      "| epoch  15 |    20/   28 batches | accuracy    0.586 | loss 1.886544\n",
      "val accuracy     0.33 | val loss 2.436482\n",
      "\n",
      "| epoch  16 |    20/   28 batches | accuracy    0.631 | loss 1.843729\n",
      "val accuracy     0.33 | val loss 2.385302\n",
      "\n",
      "| epoch  17 |    20/   28 batches | accuracy    0.633 | loss 1.751298\n",
      "val accuracy     0.35 | val loss 2.373336\n",
      "\n",
      "| epoch  18 |    20/   28 batches | accuracy    0.642 | loss 1.698449\n",
      "val accuracy     0.37 | val loss 2.384588\n",
      "\n",
      "| epoch  19 |    20/   28 batches | accuracy    0.669 | loss 1.666395\n",
      "val accuracy     0.34 | val loss 2.418554\n",
      "\n",
      "| epoch  20 |    20/   28 batches | accuracy    0.683 | loss 1.673472\n",
      "val accuracy     0.37 | val loss 2.389984\n",
      "\n",
      "| epoch  21 |    20/   28 batches | accuracy    0.697 | loss 1.677068\n",
      "val accuracy     0.36 | val loss 2.434772\n",
      "\n",
      "| epoch  22 |    20/   28 batches | accuracy    0.708 | loss 1.633715\n",
      "val accuracy     0.34 | val loss 2.503465\n",
      "\n",
      "| epoch  23 |    20/   28 batches | accuracy    0.701 | loss 1.600631\n",
      "val accuracy     0.35 | val loss 2.468143\n",
      "\n",
      "| epoch  24 |    20/   28 batches | accuracy    0.736 | loss 1.677096\n",
      "val accuracy     0.35 | val loss 2.500880\n",
      "\n",
      "| epoch  25 |    20/   28 batches | accuracy    0.726 | loss 1.681274\n",
      "val accuracy     0.36 | val loss 2.472161\n",
      "\n",
      "| epoch  26 |    20/   28 batches | accuracy    0.710 | loss 1.607769\n",
      "val accuracy     0.35 | val loss 2.418662\n",
      "\n",
      "| epoch  27 |    20/   28 batches | accuracy    0.735 | loss 1.580428\n",
      "val accuracy     0.38 | val loss 2.433541\n",
      "\n",
      "| epoch  28 |    20/   28 batches | accuracy    0.733 | loss 1.637835\n",
      "val accuracy     0.32 | val loss 2.535474\n",
      "\n",
      "| epoch  29 |    20/   28 batches | accuracy    0.752 | loss 1.492985\n",
      "val accuracy     0.34 | val loss 2.492771\n",
      "\n",
      "| epoch  30 |    20/   28 batches | accuracy    0.763 | loss 1.578885\n",
      "val accuracy     0.36 | val loss 2.452868\n",
      "\n",
      "| epoch  31 |    20/   28 batches | accuracy    0.742 | loss 1.678249\n",
      "val accuracy     0.37 | val loss 2.446840\n",
      "\n",
      "| epoch  32 |    20/   28 batches | accuracy    0.767 | loss 1.549210\n",
      "val accuracy     0.36 | val loss 2.443267\n",
      "\n",
      "| epoch  33 |    20/   28 batches | accuracy    0.766 | loss 1.679782\n",
      "val accuracy     0.37 | val loss 2.430264\n",
      "\n",
      "| epoch  34 |    20/   28 batches | accuracy    0.770 | loss 1.566739\n",
      "val accuracy     0.36 | val loss 2.482345\n",
      "\n",
      "| epoch  35 |    20/   28 batches | accuracy    0.768 | loss 1.515107\n",
      "val accuracy     0.33 | val loss 2.480559\n",
      "\n",
      "| epoch  36 |    20/   28 batches | accuracy    0.786 | loss 1.522713\n",
      "val accuracy     0.34 | val loss 2.475147\n",
      "\n",
      "| epoch  37 |    20/   28 batches | accuracy    0.773 | loss 1.521819\n",
      "val accuracy     0.34 | val loss 2.509414\n",
      "\n",
      "| epoch  38 |    20/   28 batches | accuracy    0.780 | loss 1.516420\n",
      "val accuracy     0.35 | val loss 2.423712\n",
      "\n",
      "| epoch  39 |    20/   28 batches | accuracy    0.780 | loss 1.555257\n",
      "val accuracy     0.37 | val loss 2.374722\n",
      "\n",
      "| epoch  40 |    20/   28 batches | accuracy    0.774 | loss 1.486756\n",
      "val accuracy     0.36 | val loss 2.407107\n",
      "\n",
      "| epoch  41 |    20/   28 batches | accuracy    0.780 | loss 1.511610\n",
      "val accuracy     0.37 | val loss 2.381373\n",
      "\n",
      "| epoch  42 |    20/   28 batches | accuracy    0.770 | loss 1.535499\n",
      "val accuracy     0.37 | val loss 2.417969\n",
      "\n",
      "| epoch  43 |    20/   28 batches | accuracy    0.783 | loss 1.484342\n",
      "val accuracy     0.35 | val loss 2.455956\n",
      "\n",
      "| epoch  44 |    20/   28 batches | accuracy    0.779 | loss 1.550929\n",
      "val accuracy     0.36 | val loss 2.432066\n",
      "\n",
      "| epoch  45 |    20/   28 batches | accuracy    0.776 | loss 1.528618\n",
      "val accuracy     0.35 | val loss 2.442750\n",
      "\n",
      "| epoch  46 |    20/   28 batches | accuracy    0.795 | loss 1.587370\n",
      "val accuracy     0.37 | val loss 2.405137\n",
      "\n",
      "| epoch  47 |    20/   28 batches | accuracy    0.794 | loss 1.504586\n",
      "val accuracy     0.35 | val loss 2.444460\n",
      "\n",
      "| epoch  48 |    20/   28 batches | accuracy    0.783 | loss 1.497054\n",
      "val accuracy     0.36 | val loss 2.508565\n",
      "\n",
      "| epoch  49 |    20/   28 batches | accuracy    0.783 | loss 1.485433\n",
      "val accuracy     0.35 | val loss 2.554058\n",
      "\n",
      "| epoch  50 |    20/   28 batches | accuracy    0.785 | loss 1.493394\n",
      "val accuracy     0.37 | val loss 2.443516\n",
      "\n",
      "| epoch  51 |    20/   28 batches | accuracy    0.789 | loss 1.540160\n",
      "val accuracy     0.34 | val loss 2.519744\n",
      "\n",
      "| epoch  52 |    20/   28 batches | accuracy    0.791 | loss 1.458765\n",
      "val accuracy     0.36 | val loss 2.479305\n",
      "\n",
      "| epoch  53 |    20/   28 batches | accuracy    0.797 | loss 1.496842\n",
      "val accuracy     0.35 | val loss 2.458717\n",
      "\n",
      "| epoch  54 |    20/   28 batches | accuracy    0.786 | loss 1.568450\n",
      "val accuracy     0.34 | val loss 2.444327\n",
      "\n",
      "| epoch  55 |    20/   28 batches | accuracy    0.785 | loss 1.611499\n",
      "val accuracy     0.34 | val loss 2.459521\n",
      "\n",
      "| epoch  56 |    20/   28 batches | accuracy    0.806 | loss 1.472361\n",
      "val accuracy     0.35 | val loss 2.474670\n",
      "\n",
      "| epoch  57 |    20/   28 batches | accuracy    0.794 | loss 1.546202\n",
      "val accuracy     0.38 | val loss 2.474525\n",
      "\n",
      "| epoch  58 |    20/   28 batches | accuracy    0.798 | loss 1.504262\n",
      "val accuracy     0.36 | val loss 2.438982\n",
      "\n",
      "| epoch  59 |    20/   28 batches | accuracy    0.799 | loss 1.518245\n",
      "val accuracy     0.35 | val loss 2.367186\n",
      "\n",
      "| epoch  60 |    20/   28 batches | accuracy    0.803 | loss 1.473243\n",
      "val accuracy     0.35 | val loss 2.378730\n",
      "\n",
      "| epoch  61 |    20/   28 batches | accuracy    0.800 | loss 1.449824\n",
      "val accuracy     0.36 | val loss 2.404629\n",
      "\n",
      "| epoch  62 |    20/   28 batches | accuracy    0.796 | loss 1.474705\n",
      "val accuracy     0.36 | val loss 2.420451\n",
      "\n",
      "| epoch  63 |    20/   28 batches | accuracy    0.793 | loss 1.485790\n",
      "val accuracy     0.37 | val loss 2.465680\n",
      "\n",
      "| epoch  64 |    20/   28 batches | accuracy    0.807 | loss 1.441439\n",
      "val accuracy     0.33 | val loss 2.543953\n",
      "\n",
      "| epoch  65 |    20/   28 batches | accuracy    0.809 | loss 1.505733\n",
      "val accuracy     0.35 | val loss 2.569289\n",
      "\n",
      "| epoch  66 |    20/   28 batches | accuracy    0.800 | loss 1.431503\n",
      "val accuracy     0.36 | val loss 2.474163\n",
      "\n",
      "| epoch  67 |    20/   28 batches | accuracy    0.803 | loss 1.485523\n",
      "val accuracy     0.37 | val loss 2.460319\n",
      "\n",
      "| epoch  68 |    20/   28 batches | accuracy    0.810 | loss 1.450517\n",
      "val accuracy     0.36 | val loss 2.471580\n",
      "\n",
      "| epoch  69 |    20/   28 batches | accuracy    0.808 | loss 1.505402\n",
      "val accuracy     0.35 | val loss 2.550358\n",
      "\n",
      "| epoch  70 |    20/   28 batches | accuracy    0.802 | loss 1.445286\n",
      "val accuracy     0.36 | val loss 2.496241\n",
      "\n",
      "| epoch  71 |    20/   28 batches | accuracy    0.803 | loss 1.532994\n",
      "val accuracy     0.36 | val loss 2.491362\n",
      "\n",
      "| epoch  72 |    20/   28 batches | accuracy    0.817 | loss 1.468581\n",
      "val accuracy     0.36 | val loss 2.590458\n",
      "\n",
      "| epoch  73 |    20/   28 batches | accuracy    0.807 | loss 1.484355\n",
      "val accuracy     0.38 | val loss 2.546727\n",
      "\n",
      "| epoch  74 |    20/   28 batches | accuracy    0.798 | loss 1.480661\n",
      "val accuracy     0.33 | val loss 2.545396\n",
      "\n",
      "| epoch  75 |    20/   28 batches | accuracy    0.810 | loss 1.503269\n",
      "val accuracy     0.34 | val loss 2.536720\n",
      "\n",
      "| epoch  76 |    20/   28 batches | accuracy    0.805 | loss 1.456737\n",
      "val accuracy     0.36 | val loss 2.556118\n",
      "\n",
      "| epoch  77 |    20/   28 batches | accuracy    0.817 | loss 1.479210\n",
      "val accuracy     0.35 | val loss 2.414656\n",
      "\n",
      "| epoch  78 |    20/   28 batches | accuracy    0.812 | loss 1.424229\n",
      "val accuracy     0.36 | val loss 2.444324\n",
      "\n",
      "| epoch  79 |    20/   28 batches | accuracy    0.816 | loss 1.437212\n",
      "val accuracy     0.36 | val loss 2.481093\n",
      "\n",
      "| epoch  80 |    20/   28 batches | accuracy    0.810 | loss 1.468228\n",
      "val accuracy     0.32 | val loss 2.524342\n",
      "\n",
      "| epoch  81 |    20/   28 batches | accuracy    0.811 | loss 1.512309\n",
      "val accuracy     0.35 | val loss 2.459398\n",
      "\n",
      "| epoch  82 |    20/   28 batches | accuracy    0.806 | loss 1.457282\n",
      "val accuracy     0.35 | val loss 2.514680\n",
      "\n",
      "| epoch  83 |    20/   28 batches | accuracy    0.815 | loss 1.380748\n",
      "val accuracy     0.36 | val loss 2.519341\n",
      "\n",
      "| epoch  84 |    20/   28 batches | accuracy    0.817 | loss 1.436057\n",
      "val accuracy     0.36 | val loss 2.532143\n",
      "\n",
      "| epoch  85 |    20/   28 batches | accuracy    0.818 | loss 1.444264\n",
      "val accuracy     0.35 | val loss 2.453670\n",
      "\n",
      "| epoch  86 |    20/   28 batches | accuracy    0.811 | loss 1.459780\n",
      "val accuracy     0.37 | val loss 2.489506\n",
      "\n",
      "| epoch  87 |    20/   28 batches | accuracy    0.826 | loss 1.372337\n",
      "val accuracy     0.36 | val loss 2.474274\n",
      "\n",
      "| epoch  88 |    20/   28 batches | accuracy    0.812 | loss 1.512077\n",
      "val accuracy     0.31 | val loss 2.519313\n",
      "\n",
      "| epoch  89 |    20/   28 batches | accuracy    0.815 | loss 1.473475\n",
      "val accuracy     0.34 | val loss 2.434657\n",
      "\n",
      "| epoch  90 |    20/   28 batches | accuracy    0.821 | loss 1.457472\n",
      "val accuracy     0.37 | val loss 2.429275\n",
      "\n",
      "| epoch  91 |    20/   28 batches | accuracy    0.825 | loss 1.439057\n",
      "val accuracy     0.36 | val loss 2.447100\n",
      "\n",
      "| epoch  92 |    20/   28 batches | accuracy    0.826 | loss 1.416553\n",
      "val accuracy     0.36 | val loss 2.514431\n",
      "\n",
      "| epoch  93 |    20/   28 batches | accuracy    0.820 | loss 1.407199\n",
      "val accuracy     0.36 | val loss 2.453858\n",
      "\n",
      "| epoch  94 |    20/   28 batches | accuracy    0.824 | loss 1.436594\n",
      "val accuracy     0.34 | val loss 2.564469\n",
      "\n",
      "| epoch  95 |    20/   28 batches | accuracy    0.819 | loss 1.499251\n",
      "val accuracy     0.38 | val loss 2.455030\n",
      "\n",
      "| epoch  96 |    20/   28 batches | accuracy    0.818 | loss 1.410193\n",
      "val accuracy     0.35 | val loss 2.426245\n",
      "\n",
      "| epoch  97 |    20/   28 batches | accuracy    0.820 | loss 1.401506\n",
      "val accuracy     0.35 | val loss 2.542221\n",
      "\n",
      "| epoch  98 |    20/   28 batches | accuracy    0.825 | loss 1.407466\n",
      "val accuracy     0.39 | val loss 2.414221\n",
      "\n",
      "| epoch  99 |    20/   28 batches | accuracy    0.826 | loss 1.505366\n",
      "val accuracy     0.35 | val loss 2.494329\n",
      "\n",
      "| epoch 100 |    20/   28 batches | accuracy    0.825 | loss 1.431512\n",
      "val accuracy     0.34 | val loss 2.528502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 120 # epoch\n",
    "\n",
    "model = LSTMcustom(word_vec=word_emb, embed_dim=EMBEDDING_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "total_accu = None\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "id": "JXRqDqRYVgou"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy     0.32 | val loss 2.448810\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(test_loader)\n",
    "# print('test accuracy {:8.2f}%'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
