{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C-bNwvsihO0H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\"\"\"!pip install bs4 \n",
        "!pip install sklearn\n",
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install lxml\"\"\"\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "import lxml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from gensim.models import doc2vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ndKDctEkT6L",
        "outputId": "2b3b4866-c519-4afe-cfd8-553190f11f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "unzip:  cannot find or open mbti_1.csv.zip, mbti_1.csv.zip.zip or mbti_1.csv.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download datasnaek/mbti-type\n",
        "! unzip mbti_1.csv.zip\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "yXqUnaeRhmNu",
        "outputId": "6cb627ea-78d6-4388-c095-0a4b69bb3401"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file=\"/Users/placid_brain/Documents/SUTD/Term 6/Computational Data Science/Week 10/mbti_1.csv\"\n",
        "df = pd.read_csv(file)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7LejRcCepS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fto4LDyVkABC",
        "outputId": "e5a238a3-0a1b-4227-b706-5e8b1c489b52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/placid_brain/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    \n",
        "    text = text.lower() # lowercase text\n",
        "    \n",
        "    \n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nVWkOQBxlIYY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>http wwwyoutubecom watchvqscwe3krw http 41medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>ENTP</td>\n",
              "      <td>finding lack posts alarming ex boring position...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>INTP</td>\n",
              "      <td>ood one _____ https wwwyoutubecom watchvfibolw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>ear enjoyed conversation day soteric gabbing n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>ENTJ</td>\n",
              "      <td>oure fired hats another silly misconception ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8670</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>https wwwyoutubecom watchvt8ed_h908 x always t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8671</td>\n",
              "      <td>ENFP</td>\n",
              "      <td>oif thread already exists someplace else http ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8672</td>\n",
              "      <td>INTP</td>\n",
              "      <td>many questions things would take purple pill i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8673</td>\n",
              "      <td>INFP</td>\n",
              "      <td>conflicted right comes wanting children honest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8674</td>\n",
              "      <td>INFP</td>\n",
              "      <td>long since personalitycafe although doesnt see...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8675 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                              posts\n",
              "0     INFJ  http wwwyoutubecom watchvqscwe3krw http 41medi...\n",
              "1     ENTP  finding lack posts alarming ex boring position...\n",
              "2     INTP  ood one _____ https wwwyoutubecom watchvfibolw...\n",
              "3     INTJ  ear enjoyed conversation day soteric gabbing n...\n",
              "4     ENTJ  oure fired hats another silly misconception ha...\n",
              "...    ...                                                ...\n",
              "8670  ISFP  https wwwyoutubecom watchvt8ed_h908 x always t...\n",
              "8671  ENFP  oif thread already exists someplace else http ...\n",
              "8672  INTP  many questions things would take purple pill i...\n",
              "8673  INFP  conflicted right comes wanting children honest...\n",
              "8674  INFP  long since personalitycafe although doesnt see...\n",
              "\n",
              "[8675 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\"\"\"for k in range(0,len(df.index)):\n",
        "  print(k)\n",
        "  print(df[\"posts\"][k])\n",
        "  df[\"posts\"][k] = clean_text(df[\"posts\"][k])\"\"\"\n",
        "\n",
        "df[\"posts\"] = df[\"posts\"].apply(clean_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JblfFzUOlawf"
      },
      "outputs": [],
      "source": [
        "x= df[\"posts\"]\n",
        "y=df[\"type\"]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I3mcAhdBlwXm"
      },
      "outputs": [],
      "source": [
        "def label_sentences(corpus, label_type):\n",
        "    \"\"\"\n",
        "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
        "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
        "    a dummy index of the post.\n",
        "    \"\"\"\n",
        "    labeled = []\n",
        "    for i, v in enumerate(corpus):\n",
        "        label = label_type + '_' + str(i)\n",
        "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
        "    return labeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SNx_jwBdl3zy"
      },
      "outputs": [],
      "source": [
        "X_train = label_sentences(x_train, 'Train')\n",
        "X_test = label_sentences(x_test, 'Test')\n",
        "all_data = X_train + X_test\n",
        "#all_data[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HVCYGpApl9tj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8675/8675 [00:00<00:00, 727028.34it/s]\n"
          ]
        }
      ],
      "source": [
        "model_dbow = doc2vec.Doc2Vec(dm=0, vector_size=100, negative=5, min_count=1, alpha=0.065, \n",
        "                     min_alpha=0.065)\n",
        "model_dbow.build_vocab([x for x in tqdm(all_data)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u64pGQyzmLfY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8675/8675 [00:00<00:00, 2268428.13it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 3313805.76it/s]\n",
            "100%|██████████| 8675/8675 [00:00<00:00, 2988303.81it/s]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), \n",
        "                     total_examples=len(all_data), \n",
        "                     epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_6sdsHZRrmP5"
      },
      "outputs": [],
      "source": [
        "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
        "    \"\"\"\n",
        "    Get vectors from trained doc2vec model\n",
        "    :param doc2vec_model: Trained Doc2Vec model\n",
        "    :param corpus_size: Size of the data\n",
        "    :param vectors_size: Size of the embedding vectors\n",
        "    :param vectors_type: Training or Testing vectors\n",
        "    :return: list of vectors\n",
        "    \"\"\"\n",
        "    vectors = np.zeros((corpus_size, vectors_size))\n",
        "    for i in range(0, corpus_size):\n",
        "        prefix = vectors_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BoGVExIDrpiL"
      },
      "outputs": [],
      "source": [
        "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 100, 'Train')\n",
        "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 100, 'Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ocAd3MgVrvGg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score as acs\n",
        "\n",
        "penalty_lst= ['none','l1','l2','elasticnet']\n",
        "c_lst = [0.1,0.5,1]\n",
        "result_dict={}\n",
        "\n",
        "def model(x_train,x_test,y_train,y_test):\n",
        "\n",
        "  for i in penalty_lst:\n",
        "    for k in c_lst:\n",
        "\n",
        "  \n",
        "\n",
        "      clf = LogisticRegression(penalty=i,C=k,solver='saga',l1_ratio=0.6)\n",
        "      clf.fit(x_train, y_train) \n",
        "      y_pred = clf.predict(x_test)\n",
        "      acs=accuracy_score(y_pred, y_test)\n",
        "      result_dict[\"Penalty value: \"+str(i),\" C value: \"+str(k)]=acs\n",
        "\n",
        " \n",
        "  return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gj7kQM_tsw9i"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1321: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/Users/placid_brain/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{('Penalty value: none', ' C value: 0.1'): 0.3284671532846715,\n",
              " ('Penalty value: none', ' C value: 0.5'): 0.3284671532846715,\n",
              " ('Penalty value: none', ' C value: 1'): 0.3284671532846715,\n",
              " ('Penalty value: l1', ' C value: 0.1'): 0.32808298117556667,\n",
              " ('Penalty value: l1', ' C value: 0.5'): 0.3296196696119862,\n",
              " ('Penalty value: l1', ' C value: 1'): 0.32769880906646176,\n",
              " ('Penalty value: l2', ' C value: 0.1'): 0.33730311179408373,\n",
              " ('Penalty value: l2', ' C value: 0.5'): 0.3311563580484057,\n",
              " ('Penalty value: l2', ' C value: 1'): 0.32885132539377643,\n",
              " ('Penalty value: elasticnet', ' C value: 0.1'): 0.3292354975028813,\n",
              " ('Penalty value: elasticnet', ' C value: 0.5'): 0.3284671532846715,\n",
              " ('Penalty value: elasticnet', ' C value: 1'): 0.32808298117556667}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(train_vectors_dbow,test_vectors_dbow,y_train,y_test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "cds project ML models.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a871dbaf8ba6363035c157814b83ea00ea26824d15029fff46b23e2e4729fcff"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
